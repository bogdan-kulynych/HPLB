
library(randomForest)
library(fields)
source("lambdahat_code.R") ## includes the gethypertv function for the basic confusion table bound
load("reanalysis/climatedata.rda") ## loads 'data', the object generated by your pre-processing


## what is missing
## 1) gethyper was lacking the adjustment witnesses->TV bound, so gets worse
## 2) or one leaves gethyper and gets a bound for witnesses instead which is also interesting

p <- nrow(data$air)
n <- ncol(data$air)

resmat <- matrix(nrow=p,ncol=2)
tvseq <- sort(unique(c(seq(0,1,by=0.01),seq(0,0.1,by=0.001),seq(0,0.2,by=0.005),c(0,0.0001,0.001,0.002,0.005,0.01,0.015,0.02))))

for (k in sample(1:p,p)){
    X <- apply(cbind( data$air[k,], data$mslp[k,], data$prate[k,], data$shum[k,]),2,diff)
    
    train <- (round(n/4):round(n*3/4)) ## mid-block for training; can change
    test <- (1:n)[-train]
    ## can also space out by
    ## test <- test[seq(1,length(test),by=3)] to reduce autocorrelation
    Y <- as.factor((1:n)>round(n/2))
    rf <- randomForest(X[train,],Y[train])
    
    
    
    pred <- predict(rf, X[test,],type="prob")
    conf <- table( Y[test], predict(rf,X[test,]))
    hyper <- gethypertv(conf)
    
    Yn <- as.numeric(Y)
    ra <- order( dp <- (pred[,1]-pred[,2]))
    fpr <- cumsum(as.numeric(Yn[test]==1)[ ra])/sum( Yn[test]==1)
    tpr <- cumsum(as.numeric(Yn[test]!=1)[ ra])/sum( Yn[test]!=1)
    auc <- max(0.5,sum(tpr*diff(c(0,fpr))))
    tvhat <- dWit( t=as.numeric(Y[test]), rho=-as.numeric(pred[,1]-pred[,2]),s=1.5, tv.seq   = tvseq)$tvhat
    
    resmat[k,] <- c(hyper, tvhat)
}

pdf(file="results_differenced.pdf",width=12,height=6)
par(mfrow=c(1,3))
plot(resmat[1:k,1],resmat[1:k,2],xlab="TV-bound (conf table)",ylab="TV-bound")
abline(c(0,1))
image.plot( matrix( resmat[,1],nrow=72),axes=FALSE,main="TV-bound (conf table)")
image.plot( matrix( resmat[,2],nrow=72),axes=FALSE,main="TV-bound")
dev.off()





